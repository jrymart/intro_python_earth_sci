{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e9e35-1823-4145-abd7-0e0f270fc05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, osr, ogr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74df77b7-bfa2-48ac-9e53-8568ddbb5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33187b-8a40-451c-95e0-d4dea4552efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f9fb2-bb86-4dc5-997d-a0ae54c44c75",
   "metadata": {
    "tags": []
   },
   "source": [
    "# How Computers Represent Photographs\n",
    "An photograph is a recording of light reflected off something (typically refered to as a scene).  When a human observes something visually, it is light reflected off objects that activates specialized cells in the retina.  Photographs work the same way, using a variety of technologies to substitute for the cells of the retina.  Traditional film photography uses a film full of light-sensitive silver salt crystal, part of which becomes metallic silver when exposed to light.  Digital photography uses an array of photosensitive circuits that record the ammount of light.  In either case, what you are left with is (typically but not necessarily) a rectangle that represents the amount of light reflected from a captured scene.\n",
    "## Rasters\n",
    "The result of a digital image is called a \"raster\" an array of values representing the ammount of light at each position.  Below is a sample raster repreented in python as a list of lists of integers.  The first list is the upper row of pixels in our image.  The top left pixel has a value of 255, meaning very bright.  The bottom right has a value of 60, rather dark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230eba14-ad47-4e31-b4d5-0fb7ce82ca4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image = [[255,200,180,180,180],\n",
    "         [200,200,100,100,100],\n",
    "         [180,180,80, 100, 80],\n",
    "         [170,170,70, 100, 60],\n",
    "         [160,160,60, 100, 60]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b132b1-8641-43d8-84cc-0fc2199b86cf",
   "metadata": {},
   "source": [
    "A typical pixel in a computer image will have values that range from 0 to 255.  Think about what we learned about how computers represent numbers.  What does this mean about the underlying data structure of a pixel?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1425aa-af60-4922-acf6-45d1c184feaf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ea6e38-0bb2-4bf9-920b-78ddcaa124d8",
   "metadata": {},
   "source": [
    "In python we can view images with a library called \"matplotlib\".  Matplotlib can do lots of things including make many different types of graphs.  Now we'll use the imshow function to display our image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "206cb9c6-819c-4ee3-adc2-c03b5815ef63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f042c7b5fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275a320-3a66-4439-9d9b-0cfbdcc4e8a5",
   "metadata": {},
   "source": [
    "Now, try to make you own \"image\" using a list of lists, and display it with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886e5d6-92f8-45ca-a68b-a3e951a49eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a34c904-0055-405d-9e17-dd5887d9e248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Color photography\n",
    "The sensors (silver salt or digitial circuit) record the *ammount* of light that hit them, not necessarily the *color* of light.  So how do we get color images?  Humans see color because specific types of cells in the retina are sensitive to specific wavelengths of light.  Humans are sensitive to red, green, and blue light (see below).\n",
    "![human color sensitivity](https://upload.wikimedia.org/wikipedia/commons/f/f1/1416_Color_Sensitivity.svg)\n",
    "Our eyes take in the ammount of red, green, and blue light in what we see, and construct color based on that.  We can mimic that with a digital image by recording the ammount of red, green, and blue light.  This can be done by filtering out different types of light, but you can think of a digital camera as, like an eye, having three different types of sensors.  When a computer displays an image, rather than each pixel representing a certain ammount of light, like in our example above, each \"pixel\" is three lights, one red, one green, and one blue.  Each light as a brightness that corresponds to the relative ammount of that color light in that part of the scene.  Put your phone screen under a microscope sometime, you'll see that it's actually made up of a bunch of red, green,. and blue lights!\n",
    "### Color rasters\n",
    "But how do we store this on a computer?  Whereas before, we had a list of lists, or an array where each value was the ammount of light reflected from a scene, instead we could have each value be a tuple contaning the ammount of red, green, and blue light!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656acc8-61af-4a4d-97c0-31bfc9e883f2",
   "metadata": {},
   "source": [
    "pixel = (120, 0, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52aab3-d458-4c79-99f2-5f0b60650190",
   "metadata": {},
   "source": [
    "This would lead us to an image that would be something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31b968e-091a-4357-9b8b-e4fa7e4f3d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_image = [[(120, 0, 120), (120, 10, 120), (120, 20, 120)],\n",
    "               [(130, 0, 120), (120, 10, 130), (130, 20, 130)],\n",
    "               [(140, 0, 120), (130, 10, 130), (140, 20, 140)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d454da-230e-4e75-9f40-469100c26fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Typically, for reasons that aren't important now, instead of images being stored as 2d arrays of tuples of 3, they are stored as 3 2d arrays, each array representing a different type of light, often called a \"band\".\n",
    "\n",
    "### Viewing images in python\n",
    "Along with this python notebook, are some image files for a satelite iamge of the Boulder area.  There are four files, each for a different band.  These files are in a \"geotiff\" format.  \"tiff\" is a commonly use duncopressed image file, and geotiff signifies that it has some additional metadata on the spatial location of the image.  This is a commonly used format for GIS raster data.  Because it's common, there are a few ways we can read this data in Python.\n",
    "First we can use the library matplot to read in the image as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8dd3be2-ba12-4fda-be10-b882fe1bf477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8551, 8703, 8644, ..., 9136, 9153, 9502],\n",
       "       [8879, 8780, 8181, ..., 9132, 9086, 9586],\n",
       "       [8584, 8247, 7888, ..., 8733, 8880, 9367],\n",
       "       ...,\n",
       "       [8083, 8396, 8903, ..., 9048, 8824, 8945],\n",
       "       [8167, 8332, 9045, ..., 8941, 8798, 9179],\n",
       "       [8252, 8182, 8477, ..., 8948, 9113, 9661]], dtype=uint16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_band = plt.imread(\"sample_landsat_Blue.TIF\")\n",
    "blue_band"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40602c0-ea7a-478b-91ee-7189c2236ef1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Above we see the different corners of the array, with many of the pixels omited.  Since this is the blue band, the numbers refer to relative ammount of blue light reflected at that part of the sattelite image. \n",
    "\n",
    "Since this is an array, we can see the dimensions by looking a the shape value, and also look at the range of values:refer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5259e71a-28be-4aa7-b834-94fadb3c9a81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blue_band' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArray dimensions: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mblue_band\u001b[49m\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimum Blue Value: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m blue_band\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum Blue Value: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m blue_band\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blue_band' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Array dimensions: %s\" % str(blue_band.shape))\n",
    "print(\"Minimum Blue Value: %d\" % blue_band.min())\n",
    "print(\"Maximum Blue Value: %d\" % blue_band.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4bfd40e-853a-46f8-8de8-c83da00895a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(blue_band, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(blue_band, cmap=\"Blues\", norm=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e748256b-fb2e-478e-a564-19eeba34adf7",
   "metadata": {},
   "source": [
    "Here we've plotted and colored the blue band with darker blues representing higher values of blue light.  The norm argunment we suplied above is how matplotlib scales the values of blue (0, 37820) between the blue colors matplotlib has.  It doesn't have 37,000 shades of blue so by passing the \"log\" norm, it assigns the values ot shades of blue on a log scale.  This makes it easier to distinguish features as compared to a linear scale.  Why do you think this might be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56a04b-8301-45e8-874d-9665438ae850",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b7c088a-93cf-4cf5-8361-686c18fcc504",
   "metadata": {},
   "source": [
    "Try plotting a different color band with the imshow function.  Play around with the different arguments available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e238b8f-b7ee-4269-9f2b-4b04bac137c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feb692ae-c127-417d-a38f-388009b9cefb",
   "metadata": {},
   "source": [
    "## From images to spectral data\n",
    "Sure humans typically only distinguish between red, green, and blue light, but we can build sensors to distinguish between all sorts of different parts of the electromagnetic spectrum.\n",
    "![the electromagnetic spectrum](https://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Electromagnetic-Spectrum.svg/1024px-Electromagnetic-Spectrum.svg.png)\n",
    "A common \"band\" of the spectrum of interest to a wide range of scientists is the \"infrared\" section, netween visible light and radio waves.  This section of the spectrum can capture thermal radiation, like the heat off of a body (ever seen a picture from \"night vision\" goggles?\" and has a wide range of applications, including vegetation health.\n",
    "\n",
    "The satelite (Landsat 8) that captured the sattelite image of Boulder contains a few bands beyond the visible spectrum.  We've included the near infrared band, but read about the Landsat satelite and other bands it includes.  Do you have any ideas about how you could use other bands?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f5a90-339b-4591-a3dd-d3811cbd5839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
